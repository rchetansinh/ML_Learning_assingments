# -*- coding: utf-8 -*-
"""Main Assignment for Python for Data Science_pragnesh.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XCZVw_Ol90-J17meSmVfwgeBlXapCsaf

####FINAL ASSIGNMENT

#1. Using Python script as a calculator for the below tasks:

  a. Create the variables n, r, p and assign them values 10, 5, and 100 respectively.

  Then evaluate the following expression in the Python console.

  ùê¥ = ùëù (1 + ùëü/ 100) ùëõ

  b. What are the data types of the variables p, r, n, and A in problem (1(a))?

  c. If the data type of the variable ‚Äòn‚Äô is not integer, then redefine ‚Äòn‚Äô as integer with its value being 10 and again compute the value of A.
"""

import math

n = 10 
r = 5
p = 100

def calc(n,r,p):

  #==> If in qustion the n is power than this is solution
  v = (p*(1+(r/100)))
  A = pow(v,n)

  #==> or this is the solution

  #A = (p*(1+(r/100)))*n
  #print(A)
  
  return A

A =calc(n,r,p)  
print("Value of A:",A)

#===> Data types of vriable p ,r,n and A 

print("Datatypes of p:",type(p))
print("Datatypes of r:",type(r))
print("Datatypes of n:",type(n))
print("Datatypes of A:",type(A))

#==>If the data type of the variable ‚Äòn‚Äô is not integer, then redefine ‚Äòn‚Äô as integer with its value being 10 and again compute the value of A.

n = 10.0
print(type(n))
n = int(n)
A=calc(n,r,p)
print(type(A))

"""#2. What will be the output of the following code?

  import os

  import numpy as np

  mylist1=[2,7,3,5,4,6]

  print(mylist1)

  arr_1 = numpy.array(mylist1,dtype= int)

  print(arr_1)

"""

#Ans: With this above code we will get error numpy is not define the reason is here we import numpy but gave it alis if we need this code to work we need to import numpy ,no need to give import numpt as np

"""#3. Create a string called ‚Äòstring‚Äô with the value as ‚ÄúMachine Learning‚Äù. Which code(s) is/are appropriate to slice the sub-string ‚ÄúLearn‚Äù?"""

string = "Machine Learning"
l=string.split(" ")[-1][:5]
l

"""#4. Create a sequence of numbers from 15 to 25 and increment by 4. What is the index of the value 19?"""

#num = []
for i in range(15,26,4):
  num.append(i)

print(num)
num.index(19)

"""#5. Which of the following is true with respect to the below codes?
  num1 = 5 ** 4
  
  num2 = pow(5,4)

  print(num1,num2)

A. num1 = num2

B. num1 ‚â†num2

C. num1 <num2

D. num1 >num2

###answer :  num1 = num2

#6. We have two lists. L1 = ['Coffee', 'Tea'] L2 = ['Hot', 'Ice']. Using a nested while loop compute the following output:
Coffee
* Hot
* Ice

Tea
* Hot
* Ice
"""

L1 = ["Coffee","Tea"]
L2 = ["Hot","Ice"]
'''
outer = 0 
while L1:
  print(L1.pop(outer))
  for i in L2:
    print(" *",i)
'''

x= 0 
while x!= 2 :
  print(L1[x])
  i=0
  while i != 2:
    print(f"* {L2[i]}")
    i+=1
  x+=1

"""#Note: For Q7 and Q8, you cannot use built-in functions or NumPy or Pandas!

7. Write a function which finds all Pythagorean triplets of triangles whose sides are no greater than a natural number N.

"""

def pythagoreanTriplets(limits) :
    c, m = 0, 2
    # Limiting c would limit
    # all a, b and c
    while c < limits :
        for n in range(1, m) :
            a = m * m - n * n
            b = 2 * m * n
            c = m * m + n * n
            # if c is greater than
            # limit then break it
            if c > limits :
                break
            print(a, b, c)
        m = m + 1
 
 

limit = 20
pythagoreanTriplets(limit)

"""#8. Given a list of integers, write a function that finds the smallest and the largest value of this list. Given a list of numbers, write a function which finds their standard deviation."""

l = [2,4,6,8,9,3,6,99]



#for Max value
def Max(l):
  max = l[0]
  for i in l: 
    if i > max:
      max = i
  return max    


#For Min value
def Min(l):
  min = l[0]
  for i in l:
    if i < min:
      min = i
  return min

def std(l):
  mean = sum(l) / len(l)
  #print(mean)
  varience =sum([((x-mean) ** 2) for x in l])/len(l)
  #print(varience)
  std = varience ** .5
  #print(std)
  return std

print("Max value is:",Max(l))  
print("Min value is:",Min(l))
print("STd is:",std(l))

#import statistics
#print(statistics.stdev(l))

"""#9. There are 3 arrangements of the word DAD, namely DAD, ADD, and DDA. How many arrangements are there of the word ENDURINGLY?

"""

str1 = "ENDURINGLY"
#str1 = "DAD"

#list1=[''.join(p) for p in permutations(str1)]
#print(set(list1))
l=[]
for i in str1:
    l.append(i)
print(l)
from itertools import permutations

per = permutations(l,len(l))

cout = 0 
for i in per:
  cout+=1
  #print(i)

#here N is repting two time so we have do devide with 2!

cout = cout/(1*2)
print("Number is arrangement for word is :",cout)

"""# 9. There are 13 men and 12 women in a ballroom dancing class. If 6 men and 6 women are chosen and paired off, how many pairings are possible?

#ANS:
* for selcting 6 man from 13 man 
  13!/(13-6)!*6!
  =1716
* for selcting 6 woman from 12 woman is
  12!/(12-6)!*6!
  =924
* pairing can be done in 6! = 720
possible pairing is: 1716*924*720 = 1141620480

#11. Suppose you are taking a multiple-choice test with 4 choices for each question. In answering a question on this test, the probability that you know the answer is 0.33. If you don‚Äôt know the answer, you choose one at random. What is the probability that you knew the answer to a question, given that you answered it correctly?

#ANS:

E1- Event of choosing an answer right
E2- Event of knowing the answer
A- event of answering correct

P(E1) = 1/4 ,
P(E2) = 2/3

P(A/E1) = probability of answering correct when I know the answer  = 1
P(A/E2) = probability of answering it correct  = 2/3

p(A) - probability of answering correct = P(E1) P(A/E1)/((P(E1) P(A|E1)+P(E2) P(A | E2))
"""

round((1/3 * 1)/((1/3*1)+(2/3*2/3)),3)

"""#12. Read the given data ‚ÄòTIPS.csv‚Äô as a dataframe named Tips and answer the following question:
a) In the tips dataframe, for the variable ‚Äútotal bill‚Äù what is the 3rd quartile and maximum value?

b) The range of the variable ‚ÄúTotalBill‚Äù?
"""

import pandas as pd

df = pd.read_csv("/content/Tips.csv")
df.head()
df=df.dropna()

print("3rd quartile is:",df.TotalBill.quantile([.75])) # 3rd quartile
print("Max values is:",df.TotalBill.max())            # maximum value?

#Here we find range of col Totalbill

print("Range of Total bill is:",df.TotalBill.max()-df.TotalBill.min())

"""#13. A normal distribution which has a mean of 50 and standard deviation of 7 is taken into consideration. 68% of the distribution can be found between what two numbers?

a. 40 and 60

b. 0 and 43

c. 0 and 68

d. 43 and 57

#AND: 

According to Norman distibustion 68-95-99.7 rule 
in this case in 1 standard deviation we will have 68% os here

mean = 50 
std =7 

#nagetive part
7-50 = 43
#postive side 
7+57 = 57 


#ANS d) 43 and 57

#14. Consider the data X = (58,59,63,60,60,63,60,57,58,59). An unbiased estimation for population variance would be ____
"""

l = [58,59,63,60,60,63,60,57,58,59]

#verience = E(x - mean)**2/n-1

mean = sum(l) / len(l)
k = []
for i in l: 
  k.append((i-mean)**2)

x = sum(k) 
y=len(l) - 1
verience = x/y
verience

"""#15.From the given below boxplot identify the median value and the outlier

#ANS 
median is between 25 - 30 

outliers is above 78 and below 3 (rough vlaues from Image)

#16. Create a dictionary ‚ÄòCountry‚Äô that maps the following countries to their capitals respectively:
Country India China Japan Qatar France
State Delhi Beijing Tokyo Doha Marseilles
Find 2 commands to replace ‚ÄúMarseilles‚Äù with ‚ÄúParis‚Äù.
"""

Country = {"India" : "Delhi", 
           "China" : "Beijing",
           "Japan" : "Tokyo",
           "Qatar" : "Doha",
           "France": "Marseilles"
           }

Country["France"] = "Paris"
print("AFter replce dic is:",Country)

#Country = dict(zip(list(Country.keys()), ["Marseilles"]))
#print("AFter replce again with 2nd method",Country)

Country.update({"France":"Paris"})

"""#17. Create the tuples given below

tuple_1 = (1,5,6,7,8)

tuple_2 = (8,9,4)

Identify which of the following code does not work on a tuple.

a) sum(tuple_1)
b) len(tuple_2)
c) tuple_2 + tuple_1
d) tuple_1[3] = 45
"""

tuple_1 = (1,5,6,7,8)

tuple_2 = (8,9,4)

sum(tuple_1)
len(tuple_2)
tuple_2 + tuple_1
tuple_1[3] = 45

#ANS : d) tuple we can't modify

"""#18. How many elements in the following data structure?

s = {1,2,3,4,4,4,5,6}
"""

#by seeing this data structure looks like 8 but this is set so set will remove dublicate element 

s = {1,2,3,4,4,4,5,6}
len(s)

#ANS : 6

"""#19. Create an array with whole numbers values from 0 to 10 and find what is the command to extract the elements in the following sequence - array ([7,4,1])"""

import numpy as np

arr = np.arange(1,11)
arr=arr[::-1][::3][1:]
arr

"""#20. Create a 2-dimensional array with 3 rows and 3 columns containing random numbers from 1 to 9. Find the difference between the maximum element across the columns and the minimum element across the rows.

"""

import numpy as np

arr = np.random.randint(1,10,size=(3,3),)
print("arry is:",arr)
max = arr[:,[0,1,2]].max()
print("max is col",max)
min = arr[[0,1,2],:].min()
print("mim in row :",min)
dif = max - min
print("Difference is:",dif)

"""#21. Consider the following data to answer the question below What is the command to convert the above dictionary into a dataframe named ‚Äòdf_state‚Äô?

state_data={"state":["goa","goa","goa","gujrat","gujrat","gujrat"],
            "year" :[2010,2011,2012,2013,2014,2015],
            "pop":[2.5,2.7,4.6,3.4,3.9,4.2,],}
"""

import pandas as pd 
state_data={"state":["goa","goa","goa","gujrat","gujrat","gujrat"],
            "year" :[2010,2011,2012,2013,2014,2015],
            "pop":[2.5,2.7,4.6,3.4,3.9,4.2,],}

df_state = pd.DataFrame(data = state_data)
df_state

"""#22. List 3 commands to display the columns of the above dataframe df_state."""

df_state.iloc[:,:1]
df_state.state
df_state.loc[:, ['state', 'pop']]

df_state.columns

"""#23 . Correlation between two variables X&Y is 0.85. Now, after adding the value 2 to all the values of X, the correlation co-efficient will be______

"""

#ANS is 0.85

"""#24. A) Read the given dataset ‚ÄúTips.csv‚Äù as a dataframe ‚ÄúData‚Äù. Give 3 commands to extract the columns in the following sequence - Time, TotalBill, Tips?

#B) Read the given excel sheet ‚ÄòTips1.xlsx‚Äô as a dataframe ‚ÄòData1‚Äô. What command should be given to merge the two data frames ‚ÄòData‚Äô and ‚ÄòData1‚Äô by columns?

#C) Copy the 'Data2' dataframe as 'Data3‚Äô. (Data3 = Data2.copy()) and identify the command to find the total tips received across Day‚Äôs from the dataframe ‚ÄòData3‚Äô?
"""

import pandas as pd

#Question 1

data = pd.read_csv("/content/Tips.csv",usecols=["Time","TotalBill","Tips"])
data.reindex(columns=["Time","TotalBill","Tips"])


#Question 2
data = pd.read_csv("/content/Tips.csv")
data1 = pd.read_excel("/content/Tips1.xlsx")
#data1
#data
pd.concat([data, data1], axis=1, ignore_index=True)

#Question 3 
Data3 = data.copy()
Totaltips=Data3.Tips.max()
Totaltips

"""#25) Data Visualization Problem Statement

‚ÄòStock_File_1‚Äô, a stock trend forecasting company has just employed you as a Data Scientist. As a first task in your new job, your manager has provided you with a company‚Äôs stock data and asked you to check the quality of the data for the next step of analysis. Following are the additional description and information about the data which your manager has shared with you.

a) The data set contains six variables namely

i. Date

ii. Open

iii. High

iv. Low

v. Close

vi. Volume

b) Typically, the stock market opens at 9:15 hours and closes at 15:30 hours. Each
stock is defined by an opening price and a closing price which are the prices it opens
and closes with. Within the operating hours, the stock price touches a maximum
and minimum which are the highest and lowest prices achieved by the stock in the
working hours of the stock market. You have access to ten years of monthly stock
price data with the Open, High, Low and Close price and the number of stocks
traded for each day given by the feature Volume. On some days when there is no
trading, the parameters Open, High, Low and Close remain constant and Volume is
zero.

Furthermore, your manager also claims that the model prediction is too bad since the data is
polluted. Try to impress your new boss by preprocessing the data and by giving a proper
rationale behind the steps you would follow. The two datasets should be merged before
preprocessing.

#REGRESSION Problem Statement

Predicting the compressive strength of concrete given its composition and its age.

#Variable description

Parameter Description
Cement Cement (kg in a m3 mixture)
BFSlag Blast Furnace Slag ‚Äì non-metallic co-product produced during a furnace
operation (kg in a m^3 mixture)
FlyAsh Fly Ash ‚Äì Ash produced from burning coal (kg in a m3 mixture)
Water Water (kg in a m3 mixture)
Superplasticizer Superplasticizer ‚Äì Additive for preventing aggregate formation (kg in a m^3
mixture)

CoarseAggregate Coarse Aggregate - typically gravel (kg in a m3 mixture)
FineAggregate Fine Aggregate ‚Äì crushed stone or sand between 9.5 mm and 75 ¬µm (kg in a m3
mixture)
Age Age (day)
Ccstrength Concrete compressive strength(MPa, megapascals)

"""

import pandas as pd

data_stock_1 = pd.read_csv("/content/Stock_File_1.csv")

data_stock_1.head()
data_stock_1.shape
data_stock_1.isna().sum()
new_data_stock_1=data_stock_1.dropna(axis=0)
new_data_stock_1.isna().sum()

data_cement = pd.read_csv("/content/Concrete Compressive Strength.csv")

data_cement.head()
data_cement.columns=['Comp1_cem','Comp2_Blast','Comp3_Ash','Comp4_water','Comp5_plasticizer','Comp6_Coarse','Comp7_Agg','Age','CCS']

"""#26.The total number of missing values within the dataset"""

data_cement.isna().sum()

"""#27.Which column / feature requires correction in the type of value they hold"""

data_cement.info()

#No need any cirrection all are currect only

"""#28.After imputation of nulls with mean what is the average value of the compressive strength in concrete?"""

data_cement['CCS'].mean()

"""#29. The feature that has a moderately strong relationship with compressive strength in concrete is"""

data_cement.corr()

"""#30. Standardize the dataset using standardscaler(), split the dataset into train and test of proportions 70:30 and set the random state to 1. Build a Linear Regression Model on the data and the resulting r-squared value is between which range?"""

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaled_data = scaler.fit_transform(data_cement.iloc[:,:-1])

df_cem1=pd.DataFrame(scaled_data,columns=['Comp1_cem','Comp2_Blast','Comp3_Ash','Comp4_water','Comp5_plasticizer','Comp6_Coarse','Comp7_Agg','Age'])
df_cem1

df_cem2=pd.concat([df_cem1,data_cement.iloc[:,-1]],axis=1)

from sklearn.model_selection import train_test_split

x=df_cem2.iloc[:,:-1]
y=df_cem2.iloc[:,-1]
x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=1,test_size=0.3)

y_test

from sklearn.linear_model import LinearRegression
import sklearn.metrics

LR=LinearRegression()
LR.fit(x_train,y_train)
ypred=LR.predict(x_test)

import math
print("MSE",sklearn.metrics.mean_squared_error(ypred,y_test))
print("Mean Absolute Error",sklearn.metrics.mean_absolute_error(y_test,ypred))
print("Root mean squared error",math.sqrt(sklearn.metrics.mean_squared_error(y_test,ypred)))
print("Rsquared",sklearn.metrics.r2_score(y_test,ypred))

import statsmodels.api as sm
x_train=sm.add_constant(x_train)
lm_l=sm.OLS(y_train,x_train).fit()
print(lm_l.summary())

"""#Unsupervised Learning MCQ Questions (Theoretical):
#31. Match the terms in Group A with the relevant terms in Group B
Group A  Group B

A. k-means   1) unsupervised learning
algorithm

B. knn      2) k is no. of clusters

C. logistic regression   3) k is no. of neighbors

D. clustering     4) logit function

#ANS 

A. k-means                     ====>   k is no. of clusters                  
B. knn                         ====>k is no. of neighbors         
C. logistic regression         ====> logit function  
D. clustering                  ====>  unsupervised learning algorithm

#32. Each centroid in K- means algorithm defines one
A. cluster

B. data point

C. two clusters

D. None of the above

#ANS D. cluster

#33.The method / metric which is NOT useful to determine the optimal number of clusters in unsupervised clustering algorithms is
A. Dendogram

B. Elbow method

C. Scatter plot

D. None of the above

#ANS C. Scatter plot

#34. In the K-means algorithm, what is the most commonly used distance metric to calculate distance between centroid of each cluster and data points?
A. Chebyshev distance

B. Manhattan

C. Euclidean

D. None of the above

#C. Euclidean

#35. Which of the following statements is not correct about k-means?
A. Accuracy of clusters are improved by scaling of attributes.

B. K-means clusters are affected by outliers.

C. K-Means clustering is NOT influenced by initial centroids which are called
cluster seeds

D. Number of clusters to be built is typically a user input and it impacts the way clusters are created.

#ANS C. K-Means clustering is NOT influenced by initial centroids which are called cluster seeds
"""